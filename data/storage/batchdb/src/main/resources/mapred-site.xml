<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:9001</value>
  </property>
  <!-- i/o properties -->
  <property>
    <name>mapred.local.dir</name>
    <value>${hadoop.mapred.dir}/local</value>
    <description>The local directory where MapReduce stores intermediate
      data files.  May be a comma-separated list of
      directories on different devices in order to spread disk i/o.
      Directories that do not exist are ignored.
    </description>
  </property>

  <property>
    <name>mapred.system.dir</name>
    <value>${hadoop.mapred.dir}/system</value>
    <description>The shared directory where MapReduce stores control files.
    </description>
  </property>

  <property>
    <name>mapred.temp.dir</name>
    <value>${hadoop.mapred.dir}/temp</value>
    <description>A shared directory for temporary files.
    </description>
  </property>

  <property>
    <name>mapred.map.tasks</name>
    <value>2</value>
    <description>The default number of map tasks per job. Ignored when mapred.job.tracker is "local".</description>
  </property>

  <property>
    <name>mapred.reduce.tasks</name>
    <value>1</value>
    <description>The default number of reduce tasks per job. Typically set to 99%
      of the cluster's reduce capacity, so that if a node fails the reduces can 
      still be executed in a single wave.
      Ignored when mapred.job.tracker is "local".
    </description>
  </property>

  <property>
    <name>mapred.task.timeout</name>
    <value>300000</value>
    <description>The number of milliseconds before a task will be
    terminated if it neither reads an input, writes an output, nor
    updates its status string.
    </description>
  </property>

  <property>
    <name>mapred.reduce.parallel.copies</name>
    <value>20</value>
    <description>The default number of parallel transfers run by reduce during the copy(shuffle) phase.</description>
  </property>

  <property>
    <name>mapred.tasktracker.map.tasks.maximum</name>
    <value>2</value>
    <description>The maximum number of map tasks that will be run
      simultaneously by a task tracker.
    </description>
  </property>

  <property>
    <name>mapred.tasktracker.reduce.tasks.maximum</name>
    <value>2</value>
    <description>The maximum number of reduce tasks that will be run
      simultaneously by a task tracker.
    </description>
  </property>

  <property>
    <name>mapred.jobtracker.completeuserjobs.maximum</name>
    <value>100</value>
    <description>The maximum number of complete jobs per user to keep around 
      before delegating them to the job history.</description>
  </property>

  <property>
    <name>mapred.job.reuse.jvm.num.tasks</name>
    <value>-1</value>
    <description>How many tasks to run per jvm. If set to -1, there is no limit.</description>
  </property>

  <property>
    <name>mapred.output.compress</name>
    <value>true</value>
    <description>Should the job outputs be compressed?
    </description>
  </property>

  <property>
    <name>mapred.output.compression.type</name>
    <value>BLOCK</value>
    <description>If the job outputs are to compressed as SequenceFiles, how should
      they be compressed? Should be one of NONE, RECORD or BLOCK.
    </description>
  </property>

  <property>
    <name>mapred.output.compression.codec</name>
    <!--
    <value>org.apache.hadoop.io.compress.DefaultCodec</value>
    -->
    <value>com.hadoop.compression.lzo.LzoCodec</value>
    <description>If the job outputs are compressed, how should they be compressed?
    </description>
  </property>

  <property>
    <name>mapred.compress.map.output</name>
    <value>true</value>
    <description>Should the outputs of the maps be compressed before being
      sent across the network. Uses SequenceFile compression.
    </description>
  </property>

  <property>
    <name>mapred.map.output.compression.codec</name>
    <!--
    <value>org.apache.hadoop.io.compress.DefaultCodec</value>
    -->
    <value>com.hadoop.compression.lzo.LzoCodec</value>
    <description>If the map outputs are compressed, how should they be compressed?</description>
  </property>

  <property>
    <name>map.sort.class</name>
    <value>org.apache.hadoop.util.QuickSort</value>
    <description>The default sort class for sorting keys.
    </description>
  </property>

  <property>
    <name>io.sort.factor</name>
    <value>25</value>
    <description>The number of streams to merge at once while sorting
          files.  This determines the number of open file handles.</description>
  </property>

  <property>
    <name>io.sort.mb</name>
    <value>250</value>
    <description>The total amount of buffer memory to use while sorting 
          files, in megabytes.  By default, gives each merge stream 1MB, which
          should minimize seeks.</description>
  </property>


  <property>
    <name>mapred.queue.names</name>
    <value>default,production,dev</value>
    <description> Comma separated list of queues configured for this jobtracker.
      Jobs are added to queues and schedulers can configure different 
      scheduling properties for the various queues. To configure a property 
      for a queue, the name of the queue must match the name specified in this 
      value. Queue properties that are common to all schedulers are configured 
      here with the naming convention, mapred.queue.$QUEUE-NAME.$PROPERTY-NAME,
      for e.g. mapred.queue.default.submit-job-acl.
      The number of queues configured in this parameter could depend on the
      type of scheduler being used, as specified in 
      mapred.jobtracker.taskScheduler. For example, the JobQueueTaskScheduler
      supports only a single queue, which is the default configured here.
      Before adding more queues, ensure that the scheduler you've configured
      supports multiple queues.
    </description>
  </property>

  <property>
    <name>mapred.child.java.opts</name>
    <value>-XX:+UseConcMarkSweepGC -XX:+UseCompressedOops -server -Xmx1024m</value>
    <description>Java opts for the task tracker child processes.  
    The following symbol, if present, will be interpolated: @taskid@ is replaced 
    by current TaskID. Any other occurrences of '@' will go unchanged.
    For example, to enable verbose gc logging to a file named for the taskid in
    /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:
    -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc
    
    The configuration variable mapred.child.ulimit can be used to control the
    maximum virtual memory of the child processes. 
    </description>
  </property>

  <property> 
    <name>mapred.jobtracker.taskScheduler</name> 
    <value>org.apache.hadoop.mapred.CapacityTaskScheduler</value> 
  </property>
<!--
  <property> 
    <name>mapred.jobtracker.taskScheduler</name> 
    <value>org.apache.hadoop.mapred.FairScheduler</value> 
  </property>

  <property> 
    <name>mapred.fairscheduler.allocation.file</name> 
    <value>/opt/hadoop/0.20.2/conf/fairscheduler.xml</value> 
  </property>

  <property> 
    <name>mapred.fairscheduler.sizebasedweight</name> 
    <value>true</value> 
  </property>

  <property> 
    <name>mapred.fairscheduler.poolnameproperty</name> 
    <value>mapred.job.queue.name</value> 
  </property>

  <property>
    <name>mapred.queue.development.acl-submit-job</name>
    <value>*</value>
    <description> Comma separated list of user and group names that are allowed
      to submit jobs to the 'default' queue. The user list and the group list
      are separated by a blank. For e.g. alice,bob group1,group2. 
      If set to the special value '*', it means all users are allowed to 
      submit jobs. 
    </description>
  </property>

  <property>
    <name>mapred.queue.production.acl-submit-job</name>
    <value>*</value>
    <description> Comma separated list of user and group names that are allowed
      to submit jobs to the 'default' queue. The user list and the group list
      are separated by a blank. For e.g. alice,bob group1,group2. 
      If set to the special value '*', it means all users are allowed to 
      submit jobs. 
    </description>
  </property>
-->

  <property>
    <name>hadoop.job.ugi</name>
    <value>moom,moom</value>
  </property>
</configuration>
